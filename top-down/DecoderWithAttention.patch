--- /scratch/ph1130/show-attend-tell/models.py
+++ /scratch/ph1130/show-attend-tell/models.py
@@ -38,6 +38,21 @@
         self.embedding.weight.data.uniform_(-0.1, 0.1)
         self.fc.bias.data.fill_(0)
         self.fc.weight.data.uniform_(-0.1, 0.1)
+
+    def load_pretrained_embeddings(self, embeddings):
+        """
+        Loads embedding layer with pre-trained embeddings.
+        :param embeddings: pre-trained embeddings
+        """
+        self.embedding.weight = nn.Parameter(embeddings)
+
+    def fine_tune_embeddings(self, fine_tune=True):
+        """
+        Allow fine-tuning of embedding layer? (Only makes sense to not-allow if using pre-trained embeddings).
+        :param fine_tune: Allow?
+        """
+        for p in self.embedding.parameters():
+            p.requires_grad = fine_tune
 
     def init_hidden_state(self,batch_size):
         """
@@ -84,16 +99,14 @@
         # Create tensors to hold word predicion scores
         predictions = torch.zeros(batch_size, max(decode_lengths), vocab_size).to(device)
         predictions1 = torch.zeros(batch_size, max(decode_lengths), vocab_size).to(device)
-        
-        # At each time-step, pass the language model's previous hidden state, the mean pooled bottom up features and
-        # word embeddings to the top down attention model. Then pass the hidden state of the top down model and the bottom up 
-        # features to the attention block. The attention weighed bottom up features and hidden state of the top down attention model
-        # are then passed to the language model 
+        # At each time-step, pass the language model's previous hidden state,
+        # attention-weighing the encoder's output based on the decoder's previous hidden state output
+        # then generate a new word in the decoder with the previous word and the attention weighted encoding
         for t in range(max(decode_lengths)):
             batch_size_t = sum([l > t for l in decode_lengths])
             h1,c1 = self.top_down_attention(
                 torch.cat([h2[:batch_size_t],image_features_mean[:batch_size_t],embeddings[:batch_size_t, t, :]], dim=1),(h1[:batch_size_t], c1[:batch_size_t]))
-            attention_weighted_encoding = self.attention(image_features[:batch_size_t],h1[:batch_size_t])[0]
+            attention_weighted_encoding = self.attention(image_features[:batch_size_t],h1[:batch_size_t])
             preds1 = self.fc1(self.dropout(h1))
             h2,c2 = self.language_model(
                 torch.cat([attention_weighted_encoding[:batch_size_t],h1[:batch_size_t]], dim=1),
@@ -102,5 +115,5 @@
             predictions[:batch_size_t, t, :] = preds
             predictions1[:batch_size_t, t, :] = preds1
 
-        return predictions,encoded_captions, decode_lengths, sort_ind
+        return predictions, predictions1,encoded_captions, decode_lengths, sort_ind
 